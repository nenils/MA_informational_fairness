{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dice_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython import display\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from helpers.fairness.helpers import plot_distributions\n",
    "\n",
    "\n",
    "import dice_ml\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "sns.set(style=\"white\", palette=[sns.color_palette('muted')[i] for i in [0,2]], \n",
    "        color_codes=True, context=\"talk\")\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# import keras as ke\n",
    "# import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "create_gif = False\n",
    "# supress deprecation warnings from TF\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "print(f\"sklearn: {sk.__version__}\")\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"tensorflow: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.mlp_prediction import *\n",
    "\n",
    "datasetX, dataset ,target, numerical, categorical = load_and_preprocess_data('/Users/nilsness/Desktop/Uni Skripte und Folien/Masterarbeit/Programming/Loan-Approval-Prediction.csv')\n",
    "\n",
    "numerical.pop(-1)\n",
    "categorical.append('Credit_History')\n",
    "\n",
    "print(numerical, categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape\n",
    "dataset.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of instances to remove\n",
    "num_instances = int(0.75 * len(dataset[(dataset['Gender'] == 'Female') & (dataset['Loan_Status'] == 'Y')]))\n",
    "\n",
    "# Get the indices of the instances to remove\n",
    "indices_to_remove = dataset[(dataset['Gender'] == 'Female') & (dataset['Loan_Status'] == 'Y')].sample(num_instances).index\n",
    "\n",
    "# Remove the instances from the dataset\n",
    "dataset = dataset.drop(indices_to_remove)\n",
    "\n",
    "target = dataset['Loan_Status']\n",
    "datasetX = dataset.drop(columns=['Loan_Status'])\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetX.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_encoded, x_test_encoded, y_train, y_test, Z_train, Z_test, datasetX1, target,Z, dataset_num_headers, scaler, encoder = do_it_like_numbers_do(datasetX,target,numerical, categorical)\n",
    "models, model_list, transformations = build_pipeline(numerical,categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetL = dataset.copy()\n",
    "dataset.drop(columns='Loan_Status',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_encoded[categorical] = x_train_encoded[categorical].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(dataset_num_headers)\n",
    "dataset['Predictions'] = prediction\n",
    "dataset_num_headers['Predictions'] = prediction\n",
    "cat = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Credit_History','Property_Area_Rural','Property_Area_Urban']\n",
    "dataset_num_headers[cat]=dataset_num_headers[cat].astype('category')\n",
    "dataset_num_headers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_encoded)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Berechnung der Genauigkeit\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Berechnung der Präzision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Berechnung des Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Berechnung des F1-Scores\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "# Berechnung der Ks =_(y_test, y_pred)\n",
    "\n",
    "print(\"Genauigkeit:\", accuracy)\n",
    "print(\"Präzision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(dataset_num_headers.drop(columns='Predictions'))\n",
    "pred = pd.DataFrame(pred, columns=['No', 'Yes'])\n",
    "pred = pred['Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num_headers.drop(columns='Predictions',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_instances(new_model,datasetX):\n",
    "\n",
    "    pred_ = pd.DataFrame()\n",
    "    for i in range (0, 35):\n",
    "\n",
    "        pred = new_model.predict_proba(datasetX)\n",
    "        pred = pd.DataFrame(pred, columns=['Yes','No'])\n",
    "        pred_['Prediction'+str(i)]= pred['Yes']\n",
    "\n",
    "    pred_ = pred_.mean(axis=1)\n",
    "    print(pred_)\n",
    "    datasetX['Prediction'] = pred_\n",
    "    datasetX['Loan_Status'] = datasetL['Loan_Status']\n",
    "\n",
    "\n",
    "\n",
    "    query_instances = datasetX[datasetX['Prediction']<0.5]\n",
    "\n",
    " \n",
    "    query_instances = query_instances.sort_values(by='Prediction', ascending=False)\n",
    "    query_instances_sparsity = query_instances.copy()\n",
    "    query_instances_sparsity = query_instances_sparsity[query_instances_sparsity['Gender']==1]\n",
    "    #print(query_instances)   \n",
    "    query_instances = query_instances.iloc[[-1,0]]\n",
    "    \n",
    "\n",
    "    query_instances_sparsity.drop(columns=['Prediction'], inplace = True)\n",
    "\n",
    "    query_instances_sparsity.drop(columns=['Loan_Status'], inplace = True)\n",
    "    query_instances.drop(columns=['Loan_Status'], inplace = True)\n",
    "    query_instances.drop(columns=['Prediction'], inplace=True)\n",
    "\n",
    "    num_duplicates = len(query_instances_sparsity) // len(query_instances.iloc[[0]])\n",
    "\n",
    "    # Duplicate the DataFrame by concatenating it with itself\n",
    "    duplicated_instances = pd.concat([query_instances.iloc[[0]]] * num_duplicates, ignore_index=True)\n",
    "\n",
    "\n",
    "    # Trim the duplicated DataFrame to match the length of query_instances_sparsity\n",
    "    duplicated_instances = duplicated_instances[:len(query_instances_sparsity)]\n",
    "\n",
    "    from helpers.analysis import sparsity\n",
    "    sparsity = sparsity(query_instances_sparsity,query_instances_sparsity, duplicated_instances)\n",
    "\n",
    "  \n",
    "    while len(query_instances) < 3:\n",
    "\n",
    "        sparse_index = list(sparsity.keys())[list(sparsity.values()).index(min(sparsity.values()))]\n",
    "\n",
    "        print(sparse_index)\n",
    "        print(query_instances_sparsity.iloc[[sparse_index]])\n",
    "    \n",
    "        if new_model.predict(query_instances_sparsity.iloc[[sparse_index]])[0] < 0.5:\n",
    "            query_instances = query_instances.append(query_instances_sparsity.iloc[[sparse_index]])\n",
    "        else:\n",
    "            query_instances_sparsity.drop(query_instances_sparsity.index[sparse_index], inplace=True)\n",
    "    \n",
    "    query_instances = query_instances.drop_duplicates()\n",
    "\n",
    "    factuals = query_instances.copy()\n",
    "    \n",
    "\n",
    "\n",
    "    #query_instances.drop(columns=['Loan_Status'], inplace=True)\n",
    "   \n",
    "    datasetX.drop(columns=['Prediction'],inplace=True)\n",
    "    datasetX.drop(columns=['Loan_Status'],inplace=True)\n",
    "    \n",
    "    return query_instances, factuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instances , factuals = get_query_instances(model,dataset_num_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(query_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(query_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num_headers['Loan_Status'] = target\n",
    "dataset_num_headers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_num_headers [cat] = dataset_num_headers[cat].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = 'sklearn'\n",
    "\n",
    "# Step 2: dice_ml.Model\n",
    "m = dice_ml.Model(model=model, backend=backend) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetX['Loan_Status'] = target\n",
    "d = dice_ml.Data(dataframe=dataset_num_headers, continuous_features=['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']\n",
    "                 , outcome_name='Loan_Status', feature_names=list(dataset_num_headers.columns), categorical_features=cat,\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate DiCE\n",
    "exp_random = dice_ml.Dice(d, m, method=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instances[cat] = query_instances[cat].astype('float')\n",
    "\n",
    "query_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate counterfactuals\n",
    "dice_exp_random = exp_random.generate_counterfactuals(query_instances, total_CFs=1, desired_class=\"opposite\", verbose=True,\n",
    "                                                    proximity_weight=100.0, diversity_weight=0.2, random_seed=42,\n",
    "                                                    stopping_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_exp_random.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_exp_recourse = exp_random.generate_counterfactuals(query_instances, total_CFs=1, desired_class=\"opposite\", verbose=True,\n",
    "                                                        features_to_vary=['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Credit_History'],\n",
    "                                                       proximity_weight=1.5, diversity_weight=0.2, categorical_penalty=0.5, random_seed=42, \n",
    "                                                       sample_size=480, stopping_threshold=0.5, posthoc_sparsity_param=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_exp_recourse.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals = dice_exp_recourse.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "counterfactuals = json.loads(counterfactuals)\n",
    "\n",
    "cfs_list = counterfactuals['cfs_list']\n",
    "\n",
    "cfs_1 = pd.DataFrame(cfs_list[0], columns=['Gender', 'Married','Dependents', 'Education', 'Self_Employed', 'ApplicantIncome', \n",
    "                                            'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History','Property_Area_Rural' ,'Property_Area',\n",
    "                                            'Property_Area_Urban'\n",
    "                                            , 'Loan_Status'])\n",
    "cfs_2= pd.DataFrame(cfs_list[1], columns=['Gender', 'Married','Dependents', 'Education', 'Self_Employed', 'ApplicantIncome', \n",
    "                                            'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History','Property_Area_Rural' ,'Property_Area',\n",
    "                                            'Property_Area_Urban'\n",
    "                                            , 'Loan_Status'])\n",
    "cfs_3= pd.DataFrame(cfs_list[2], columns=['Gender', 'Married','Dependents', 'Education', 'Self_Employed', 'ApplicantIncome', \n",
    "                                            'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History','Property_Area_Rural' ,'Property_Area',\n",
    "                                            'Property_Area_Urban'\n",
    "                                            , 'Loan_Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `scaler` is the MinMaxScaler object used to scale the data\n",
    "rescaled_query_instances = scaler.inverse_transform(query_instances[numerical])\n",
    "rescaled_query_instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instances_rescaled = query_instances.copy()\n",
    "query_instances_rescaled[numerical] = rescaled_query_instances\n",
    "query_instances_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_1 = pd.DataFrame([cfs_1], columns=dataset_num_headers.columns)\n",
    "cfs_2 = pd.DataFrame([cfs_2], columns=dataset_num_headers.columns)\n",
    "cfs_3 = pd.DataFrame([cfs_3], columns=dataset_num_headers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_1_rescaled = cfs_1.copy()\n",
    "cfs_2_rescaled = cfs_2.copy()\n",
    "cfs_3_rescaled = cfs_3.copy()\n",
    "\n",
    "rescaled_cfs_1 = scaler.inverse_transform(cfs_1[numerical])\n",
    "rescaled_cfs_2 = scaler.inverse_transform(cfs_2[numerical])\n",
    "rescaled_cfs_3 = scaler.inverse_transform(cfs_3[numerical])\n",
    "\n",
    "cfs_1_rescaled[numerical] = rescaled_cfs_1\n",
    "cfs_2_rescaled[numerical] = rescaled_cfs_2\n",
    "cfs_3_rescaled[numerical] = rescaled_cfs_3\n",
    "\n",
    "cfs_1_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_2_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_3_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = pd.DataFrame(cfs_1.iloc[0]).transpose()\n",
    "counter = counter.append(cfs_2.iloc[0])\n",
    "counter = counter.append(cfs_3.iloc[0])\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_rescaled = counter.copy()\n",
    "counter_rescaled[numerical] = scaler.inverse_transform(counter[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_random_locimp = dice_ml.Dice(d, m, method=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = dataset_num_headers.drop(columns='Loan_Status').columns\n",
    "feature_names.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(dataset_num_headers.drop(columns='Loan_Status').values, mode=\"classification\",categorical_features=[0,1,2,3,4,9,10,11,12], \n",
    "                                                   training_labels=datasetX['Loan_Status'], feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn (data):\n",
    "    return np.array(list(zip(1-model.predict(data),model.predict(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = explainer.explain_instance(query_instances.iloc[0,:].values, predict_fn,labels=(0,1) ,num_features=13)\n",
    "exp2 = explainer.explain_instance(query_instances.iloc[1,:].values, predict_fn,labels=(0,1), num_features=13)\n",
    "exp3 = explainer.explain_instance(query_instances.iloc[2,:].values, predict_fn,labels=(0,1), num_features=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1.show_in_notebook(show_table=True, show_all=False)\n",
    "exp2.show_in_notebook(show_table=True, show_all=False)  \n",
    "exp3.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_1 = pd.DataFrame(exp1.as_list(),columns=['Feature','Contribution'])\n",
    "explanation_2 = pd.DataFrame(exp2.as_list(),columns=['Feature','Contribution'])\n",
    "explanation_3 = pd.DataFrame(exp3.as_list(),columns=['Feature','Contribution'])\n",
    "print(explanation_1)\n",
    "print(explanation_2)\n",
    "print(explanation_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.evaluate_distance import *\n",
    "from helpers.evaluate_redundancy import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = pd.DataFrame(cfs_1.iloc[0]).transpose()\n",
    "counter = counter.append(cfs_2.iloc[0])\n",
    "counter = counter.append(cfs_3.iloc[0])\n",
    "\n",
    "counter.reset_index(drop=True, inplace=True)\n",
    "counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter[numerical] = scaler.transform(counter[numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factuals = query_instances\n",
    "factuals.reset_index(drop=True, inplace=True)\n",
    "factuals['Loan_Status'] = [0,0,0]\n",
    "factuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cf = counter.copy().drop(columns=['Loan_Status'])\n",
    "df_fc = factuals.copy().drop(columns=['Loan_Status'])\n",
    "index = df_fc.index \n",
    "df_cf.index = index\n",
    "\n",
    "categorical.append('Credit_History')\n",
    "categorical.append('Property_Area')\n",
    "numerical = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.analysis import *\n",
    "dist = Distance()\n",
    "\n",
    "distances = dist.get_evaluation(factuals,counter)\n",
    "\n",
    "sparsity = sparsity(counter,counter,factuals)\n",
    "\n",
    "validity = validity_total(counter,factuals,model)\n",
    "\n",
    "check_binary_cat = check_binary_categorical(counter, categorical)\n",
    "\n",
    "check_one_hot = check_one_hot_integrity(counter,categorical)\n",
    "\n",
    "mean_absolute_deviation_dist = madd(df_fc, df_cf,numerical,categorical,df_cf,df_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_deviation_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_binary_cat)\n",
    "print(check_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalanobis_dist = md(factuals, df_cf, df_cf, factuals)\n",
    "mahalanobis_dist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairness-in-ml_tf1.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
